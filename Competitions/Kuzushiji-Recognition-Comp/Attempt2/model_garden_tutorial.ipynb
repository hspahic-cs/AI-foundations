{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    full_name='cifar10/3.0.2',\n",
      "    description=\"\"\"\n",
      "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
      "    \"\"\",\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    data_dir='/home/harris/tensorflow_datasets/cifar10/3.0.2',\n",
      "    file_format=tfrecord,\n",
      "    download_size=162.17 MiB,\n",
      "    dataset_size=132.40 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'id': Text(shape=(), dtype=string),\n",
      "        'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      ")\n",
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "# These are not in the tfm public API for v2.9. They will be available in v2.10\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "import official.core.train_lib\n",
    "\n",
    "exp_config = tfm.core.exp_factory.get_exp_config('cascadercnn_spinenet_coco')\n",
    "tfds_name = 'cifar10'\n",
    "ds,ds_info = tfds.load(\n",
    "tfds_name,\n",
    "with_info=True)\n",
    "\n",
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "exp_config.task.model.num_classes = 10\n",
    "exp_config.task.model.input_size = list(ds_info.features[\"image\"].shape)\n",
    "exp_config.task.model.backbone.resnet.model_id = 18\n",
    "\n",
    "# Configure training and testing data\n",
    "batch_size = 128\n",
    "\n",
    "exp_config.task.train_data.input_path = ''\n",
    "exp_config.task.train_data.tfds_name = tfds_name\n",
    "exp_config.task.train_data.tfds_split = 'train'\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "\n",
    "exp_config.task.validation_data.input_path = ''\n",
    "exp_config.task.validation_data.tfds_name = tfds_name\n",
    "exp_config.task.validation_data.tfds_split = 'test'\n",
    "exp_config.task.validation_data.global_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This may be broken in Colab.\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'GPU'\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'TPU'\n",
    "else:\n",
    "  print('Running on CPU is slow, so only train for a few steps.')\n",
    "  device = 'CPU'\n",
    "\n",
    "if device=='CPU':\n",
    "  train_steps = 20\n",
    "  exp_config.trainer.steps_per_loop = 5\n",
    "else:\n",
    "  train_steps=5000\n",
    "  exp_config.trainer.steps_per_loop = 100\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = train_steps\n",
    "exp_config.trainer.validation_interval = 1000\n",
    "exp_config.trainer.validation_steps =  ds_info.splits['test'].num_examples // batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runtime': {'all_reduce_alg': None,\n",
      "             'batchnorm_spatial_persistent': False,\n",
      "             'dataset_num_private_threads': None,\n",
      "             'default_shard_dim': -1,\n",
      "             'distribution_strategy': 'mirrored',\n",
      "             'enable_xla': False,\n",
      "             'gpu_thread_mode': None,\n",
      "             'loss_scale': None,\n",
      "             'mixed_precision_dtype': 'bfloat16',\n",
      "             'num_cores_per_replica': 1,\n",
      "             'num_gpus': 0,\n",
      "             'num_packs': 1,\n",
      "             'per_gpu_thread_count': 0,\n",
      "             'run_eagerly': False,\n",
      "             'task_index': -1,\n",
      "             'tpu': None,\n",
      "             'tpu_enable_xla_dynamic_padder': None,\n",
      "             'use_tpu_mp_strategy': False,\n",
      "             'worker_hosts': None},\n",
      " 'task': {'allow_image_summary': False,\n",
      "          'allowed_mask_class_ids': None,\n",
      "          'annotation_file': 'coco/instances_val2017.json',\n",
      "          'differential_privacy_config': None,\n",
      "          'freeze_backbone': False,\n",
      "          'init_checkpoint': None,\n",
      "          'init_checkpoint_modules': 'all',\n",
      "          'losses': {'class_weights': None,\n",
      "                     'frcnn_box_weight': 1.0,\n",
      "                     'frcnn_class_loss_top_k_percent': 1.0,\n",
      "                     'frcnn_class_use_binary_cross_entropy': False,\n",
      "                     'frcnn_class_weight': 1.0,\n",
      "                     'frcnn_huber_loss_delta': 1.0,\n",
      "                     'l2_weight_decay': 4e-05,\n",
      "                     'loss_weight': 1.0,\n",
      "                     'mask_weight': 1.0,\n",
      "                     'rpn_box_weight': 1.0,\n",
      "                     'rpn_huber_loss_delta': 0.1111111111111111,\n",
      "                     'rpn_score_weight': 1.0},\n",
      "          'model': {'anchor': {'anchor_size': 3,\n",
      "                               'aspect_ratios': [0.5, 1.0, 2.0],\n",
      "                               'num_scales': 1},\n",
      "                    'backbone': {'spinenet': {'max_level': 7,\n",
      "                                              'min_level': 3,\n",
      "                                              'model_id': '49',\n",
      "                                              'stochastic_depth_drop_rate': 0.0},\n",
      "                                 'type': 'spinenet'},\n",
      "                    'decoder': {'identity': {}, 'type': 'identity'},\n",
      "                    'detection_generator': {'apply_nms': True,\n",
      "                                            'max_num_detections': 100,\n",
      "                                            'nms_iou_threshold': 0.5,\n",
      "                                            'nms_version': 'v2',\n",
      "                                            'pre_nms_score_threshold': 0.05,\n",
      "                                            'pre_nms_top_k': 5000,\n",
      "                                            'soft_nms_sigma': None,\n",
      "                                            'use_cpu_nms': False,\n",
      "                                            'use_sigmoid_probability': False},\n",
      "                    'detection_head': {'cascade_class_ensemble': True,\n",
      "                                       'class_agnostic_bbox_pred': True,\n",
      "                                       'fc_dims': 1024,\n",
      "                                       'num_convs': 4,\n",
      "                                       'num_fcs': 1,\n",
      "                                       'num_filters': 256,\n",
      "                                       'use_separable_conv': False},\n",
      "                    'include_mask': True,\n",
      "                    'input_size': [32, 32, 3],\n",
      "                    'mask_head': {'class_agnostic': False,\n",
      "                                  'num_convs': 4,\n",
      "                                  'num_filters': 256,\n",
      "                                  'upsample_factor': 2,\n",
      "                                  'use_separable_conv': False},\n",
      "                    'mask_roi_aligner': {'crop_size': 14, 'sample_offset': 0.5},\n",
      "                    'mask_sampler': {'num_sampled_masks': 128},\n",
      "                    'max_level': 7,\n",
      "                    'min_level': 3,\n",
      "                    'norm_activation': {'activation': 'swish',\n",
      "                                        'norm_epsilon': 0.001,\n",
      "                                        'norm_momentum': 0.99,\n",
      "                                        'use_sync_bn': True},\n",
      "                    'num_classes': 10,\n",
      "                    'outer_boxes_scale': 1.0,\n",
      "                    'roi_aligner': {'crop_size': 7, 'sample_offset': 0.5},\n",
      "                    'roi_generator': {'nms_iou_threshold': 0.7,\n",
      "                                      'num_proposals': 1000,\n",
      "                                      'pre_nms_min_size_threshold': 0.0,\n",
      "                                      'pre_nms_score_threshold': 0.0,\n",
      "                                      'pre_nms_top_k': 2000,\n",
      "                                      'test_nms_iou_threshold': 0.7,\n",
      "                                      'test_num_proposals': 1000,\n",
      "                                      'test_pre_nms_min_size_threshold': 0.0,\n",
      "                                      'test_pre_nms_score_threshold': 0.0,\n",
      "                                      'test_pre_nms_top_k': 1000,\n",
      "                                      'use_batched_nms': False},\n",
      "                    'roi_sampler': {'background_iou_high_threshold': 0.5,\n",
      "                                    'background_iou_low_threshold': 0.0,\n",
      "                                    'cascade_iou_thresholds': [0.6, 0.7],\n",
      "                                    'foreground_fraction': 0.25,\n",
      "                                    'foreground_iou_threshold': 0.5,\n",
      "                                    'mix_gt_boxes': True,\n",
      "                                    'num_sampled_rois': 512},\n",
      "                    'rpn_head': {'num_convs': 1,\n",
      "                                 'num_filters': 256,\n",
      "                                 'use_separable_conv': False}},\n",
      "          'name': None,\n",
      "          'per_category_metrics': False,\n",
      "          'train_data': {'apply_tf_data_service_before_batching': False,\n",
      "                         'autotune_algorithm': None,\n",
      "                         'block_length': 1,\n",
      "                         'cache': False,\n",
      "                         'cycle_length': None,\n",
      "                         'decoder': {'simple_decoder': {'attribute_names': [],\n",
      "                                                        'mask_binarize_threshold': None,\n",
      "                                                        'regenerate_source_id': False},\n",
      "                                     'type': 'simple_decoder'},\n",
      "                         'deterministic': None,\n",
      "                         'drop_remainder': True,\n",
      "                         'dtype': 'bfloat16',\n",
      "                         'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                         'enable_tf_data_service': False,\n",
      "                         'file_type': 'tfrecord',\n",
      "                         'global_batch_size': 128,\n",
      "                         'input_path': '',\n",
      "                         'is_training': True,\n",
      "                         'num_examples': -1,\n",
      "                         'parser': {'aug_rand_hflip': True,\n",
      "                                    'aug_rand_vflip': False,\n",
      "                                    'aug_scale_max': 2.5,\n",
      "                                    'aug_scale_min': 0.1,\n",
      "                                    'aug_type': None,\n",
      "                                    'mask_crop_size': 112,\n",
      "                                    'match_threshold': 0.5,\n",
      "                                    'max_num_instances': 100,\n",
      "                                    'num_channels': 3,\n",
      "                                    'pad': True,\n",
      "                                    'rpn_batch_size_per_im': 256,\n",
      "                                    'rpn_fg_fraction': 0.5,\n",
      "                                    'rpn_match_threshold': 0.7,\n",
      "                                    'rpn_unmatched_threshold': 0.3,\n",
      "                                    'skip_crowd_during_training': True,\n",
      "                                    'unmatched_threshold': 0.5},\n",
      "                         'prefetch_buffer_size': None,\n",
      "                         'seed': None,\n",
      "                         'sharding': True,\n",
      "                         'shuffle_buffer_size': 10000,\n",
      "                         'tf_data_service_address': None,\n",
      "                         'tf_data_service_job_name': None,\n",
      "                         'tfds_as_supervised': False,\n",
      "                         'tfds_data_dir': '',\n",
      "                         'tfds_name': 'cifar10',\n",
      "                         'tfds_skip_decoding_feature': '',\n",
      "                         'tfds_split': 'train',\n",
      "                         'trainer_id': None,\n",
      "                         'weights': None},\n",
      "          'use_approx_instance_metrics': False,\n",
      "          'use_coco_metrics': True,\n",
      "          'use_wod_metrics': False,\n",
      "          'validation_data': {'apply_tf_data_service_before_batching': False,\n",
      "                              'autotune_algorithm': None,\n",
      "                              'block_length': 1,\n",
      "                              'cache': False,\n",
      "                              'cycle_length': None,\n",
      "                              'decoder': {'simple_decoder': {'attribute_names': [],\n",
      "                                                             'mask_binarize_threshold': None,\n",
      "                                                             'regenerate_source_id': False},\n",
      "                                          'type': 'simple_decoder'},\n",
      "                              'deterministic': None,\n",
      "                              'drop_remainder': False,\n",
      "                              'dtype': 'bfloat16',\n",
      "                              'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                              'enable_tf_data_service': False,\n",
      "                              'file_type': 'tfrecord',\n",
      "                              'global_batch_size': 128,\n",
      "                              'input_path': '',\n",
      "                              'is_training': False,\n",
      "                              'num_examples': -1,\n",
      "                              'parser': {'aug_rand_hflip': False,\n",
      "                                         'aug_rand_vflip': False,\n",
      "                                         'aug_scale_max': 1.0,\n",
      "                                         'aug_scale_min': 1.0,\n",
      "                                         'aug_type': None,\n",
      "                                         'mask_crop_size': 112,\n",
      "                                         'match_threshold': 0.5,\n",
      "                                         'max_num_instances': 100,\n",
      "                                         'num_channels': 3,\n",
      "                                         'pad': True,\n",
      "                                         'rpn_batch_size_per_im': 256,\n",
      "                                         'rpn_fg_fraction': 0.5,\n",
      "                                         'rpn_match_threshold': 0.7,\n",
      "                                         'rpn_unmatched_threshold': 0.3,\n",
      "                                         'skip_crowd_during_training': True,\n",
      "                                         'unmatched_threshold': 0.5},\n",
      "                              'prefetch_buffer_size': None,\n",
      "                              'seed': None,\n",
      "                              'sharding': True,\n",
      "                              'shuffle_buffer_size': 10000,\n",
      "                              'tf_data_service_address': None,\n",
      "                              'tf_data_service_job_name': None,\n",
      "                              'tfds_as_supervised': False,\n",
      "                              'tfds_data_dir': '',\n",
      "                              'tfds_name': 'cifar10',\n",
      "                              'tfds_skip_decoding_feature': '',\n",
      "                              'tfds_split': 'test',\n",
      "                              'trainer_id': None,\n",
      "                              'weights': None}},\n",
      " 'trainer': {'allow_tpu_summary': False,\n",
      "             'best_checkpoint_eval_metric': '',\n",
      "             'best_checkpoint_export_subdir': '',\n",
      "             'best_checkpoint_metric_comp': 'higher',\n",
      "             'checkpoint_interval': 5000,\n",
      "             'continuous_eval_timeout': 3600,\n",
      "             'eval_tf_function': True,\n",
      "             'eval_tf_while_loop': False,\n",
      "             'loss_upper_bound': 1000000.0,\n",
      "             'max_to_keep': 5,\n",
      "             'optimizer_config': {'ema': None,\n",
      "                                  'learning_rate': {'cosine': {'alpha': 0.0,\n",
      "                                                               'decay_steps': 5000,\n",
      "                                                               'initial_learning_rate': 0.1,\n",
      "                                                               'name': 'CosineDecay',\n",
      "                                                               'offset': 0},\n",
      "                                                    'type': 'cosine'},\n",
      "                                  'optimizer': {'sgd': {'clipnorm': None,\n",
      "                                                        'clipvalue': None,\n",
      "                                                        'decay': 0.0,\n",
      "                                                        'global_clipnorm': None,\n",
      "                                                        'momentum': 0.9,\n",
      "                                                        'name': 'SGD',\n",
      "                                                        'nesterov': False},\n",
      "                                                'type': 'sgd'},\n",
      "                                  'warmup': {'linear': {'name': 'linear',\n",
      "                                                        'warmup_learning_rate': 0.0067,\n",
      "                                                        'warmup_steps': 100},\n",
      "                                             'type': 'linear'}},\n",
      "             'preemption_on_demand_checkpoint': True,\n",
      "             'recovery_begin_steps': 0,\n",
      "             'recovery_max_trials': 0,\n",
      "             'steps_per_loop': 100,\n",
      "             'summary_interval': 100,\n",
      "             'train_steps': 5000,\n",
      "             'train_tf_function': True,\n",
      "             'train_tf_while_loop': True,\n",
      "             'validation_interval': 1000,\n",
      "             'validation_steps': 78,\n",
      "             'validation_summary_subdir': 'validation'}}\n"
     ]
    },
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight('300px');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint.pprint(exp_config.as_dict())\n",
    "\n",
    "display.Javascript(\"google.colab.output.setIframeHeight('300px');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  tf.tpu.experimental.initialize_tpu_system()\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='/device:TPU_SYSTEM:0')\n",
    "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "  model_dir = tempfile.mkdtemp()\n",
    "  task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/harris/.local/lib/python3.10/site-packages/official/vision/dataloaders/tf_example_decoder.py\", line 147, in decode  *\n        parsed_tensors = tf.io.parse_single_example(\n\n    TypeError: Expected any non-tensor type, but got a tensor instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m16\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  images.dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/official/vision/tasks/maskrcnn.py:186\u001b[0m, in \u001b[0;36mMaskRCNNTask.build_inputs\u001b[0;34m(self, params, input_context, dataset_fn)\u001b[0m\n\u001b[1;32m    178\u001b[0m   dataset_fn \u001b[38;5;241m=\u001b[39m dataset_fn_lib\u001b[38;5;241m.\u001b[39mpick_dataset_fn(params\u001b[38;5;241m.\u001b[39mfile_type)\n\u001b[1;32m    180\u001b[0m reader \u001b[38;5;241m=\u001b[39m input_reader_factory\u001b[38;5;241m.\u001b[39minput_reader_generator(\n\u001b[1;32m    181\u001b[0m     params,\n\u001b[1;32m    182\u001b[0m     dataset_fn\u001b[38;5;241m=\u001b[39mdataset_fn,\n\u001b[1;32m    183\u001b[0m     decoder_fn\u001b[38;5;241m=\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mdecode,\n\u001b[1;32m    184\u001b[0m     combine_fn\u001b[38;5;241m=\u001b[39minput_reader\u001b[38;5;241m.\u001b[39mcreate_combine_fn(params),\n\u001b[1;32m    185\u001b[0m     parser_fn\u001b[38;5;241m=\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse_fn(params\u001b[38;5;241m.\u001b[39mis_training))\n\u001b[0;32m--> 186\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/official/core/input_reader.py:575\u001b[0m, in \u001b[0;36mInputReader.read\u001b[0;34m(self, input_context, dataset)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    573\u001b[0m   dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_data_source(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matched_files, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fn,\n\u001b[1;32m    574\u001b[0m                                    input_context)\n\u001b[0;32m--> 575\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode_and_parse_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_global_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43minput_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m dataset \u001b[38;5;241m=\u001b[39m _maybe_map_fn(dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_fn)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_shared_tf_data_service_between_parallel_trainers \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tf_data_service_before_batching):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/official/core/input_reader.py:476\u001b[0m, in \u001b[0;36mInputReader._decode_and_parse_dataset\u001b[0;34m(self, dataset, batch_size, input_context)\u001b[0m\n\u001b[1;32m    473\u001b[0m   ds \u001b[38;5;241m=\u001b[39m _maybe_map_fn(ds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder_fn)\n\u001b[1;32m    474\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\u001b[0;32m--> 476\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_shuffle_and_decode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(dataset):\n\u001b[1;32m    478\u001b[0m   dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_fn(dataset)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/official/core/input_reader.py:473\u001b[0m, in \u001b[0;36mInputReader._decode_and_parse_dataset.<locals>._shuffle_and_decode\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    471\u001b[0m   ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuffle_buffer_size, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_map_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoder_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/official/core/input_reader.py:34\u001b[0m, in \u001b[0;36m_maybe_map_fn\u001b[0;34m(dataset, fn)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_map_fn\u001b[39m(dataset: tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset,\n\u001b[1;32m     32\u001b[0m                   fn: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls dataset.map if a valid function is passed in.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dataset \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filer_5s8sl_.py:29\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__decode\u001b[0;34m(self, serialized_example)\u001b[0m\n\u001b[1;32m     27\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     28\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 29\u001b[0m parsed_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_single_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_example\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keys_to_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_2\u001b[39m():\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:398\u001b[0m, in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    396\u001b[0m [mismatch] \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected any non-tensor type, but got a tensor instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmismatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(mismatch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/harris/.local/lib/python3.10/site-packages/official/vision/dataloaders/tf_example_decoder.py\", line 147, in decode  *\n        parsed_tensors = tf.io.parse_single_example(\n\n    TypeError: Expected any non-tensor type, but got a tensor instead.\n"
     ]
    }
   ],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.shape: {str(labels.shape):16}  labels.dtype: {labels.dtype!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(images.numpy().flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_info = ds_info.features['label']\n",
    "label_info.int2str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(images, labels, predictions=None):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  min = images.numpy().min()\n",
    "  max = images.numpy().max()\n",
    "  delta = max - min\n",
    "\n",
    "  for i in range(12):\n",
    "    plt.subplot(6, 6, i + 1)\n",
    "    plt.imshow((images[i]-min) / delta)\n",
    "    if predictions is None:\n",
    "      plt.title(label_info.int2str(labels[i]))\n",
    "    else:\n",
    "      if labels[i] == predictions[i]:\n",
    "        color = 'g'\n",
    "      else:\n",
    "        color = 'r'\n",
    "      plt.title(label_info.int2str(predictions[i]), color=color)\n",
    "    plt.axis(\"off\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:36:38.323117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/tmp/ipykernel_127180/3703986970.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  show_batch(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:34:14.615716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10));\n",
    "for images, labels in task.build_inputs(exp_config.task.validation_data).take(1):\n",
    "  show_batch(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2024-01-31 18:37:07.443925: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring or initializing model...\n",
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Customized initialization is done through the passed `init_fn`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:      0 | training until step 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:37:10.060399: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-01-31 18:37:10.194770: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:    100 | steps/sec:   15.8 | output: \n",
      "    {'accuracy': 0.22195312,\n",
      "     'learning_rate': 0.09990134,\n",
      "     'top_5_accuracy': 0.72976565,\n",
      "     'training_loss': 2.5345368}\n",
      "saved checkpoint to /tmp/tmprhf7315d/ckpt-100.\n",
      "train | step:    200 | steps/sec:   63.9 | output: \n",
      "    {'accuracy': 0.2315625,\n",
      "     'learning_rate': 0.09960574,\n",
      "     'top_5_accuracy': 0.76375,\n",
      "     'training_loss': 2.5171087}\n",
      "train | step:    300 | steps/sec:   84.6 | output: \n",
      "    {'accuracy': 0.29242188,\n",
      "     'learning_rate': 0.09911436,\n",
      "     'top_5_accuracy': 0.8209375,\n",
      "     'training_loss': 2.2078834}\n",
      "train | step:    400 | steps/sec:   72.2 | output: \n",
      "    {'accuracy': 0.3328125,\n",
      "     'learning_rate': 0.09842916,\n",
      "     'top_5_accuracy': 0.8442969,\n",
      "     'training_loss': 2.1127546}\n",
      "train | step:    500 | steps/sec:   75.9 | output: \n",
      "    {'accuracy': 0.336875,\n",
      "     'learning_rate': 0.09755283,\n",
      "     'top_5_accuracy': 0.850625,\n",
      "     'training_loss': 2.0769699}\n",
      "train | step:    600 | steps/sec:   94.2 | output: \n",
      "    {'accuracy': 0.346875,\n",
      "     'learning_rate': 0.096488826,\n",
      "     'top_5_accuracy': 0.8525781,\n",
      "     'training_loss': 2.0398922}\n",
      "train | step:    700 | steps/sec:   93.1 | output: \n",
      "    {'accuracy': 0.37085938,\n",
      "     'learning_rate': 0.09524136,\n",
      "     'top_5_accuracy': 0.856875,\n",
      "     'training_loss': 2.0035925}\n",
      "train | step:    800 | steps/sec:   79.9 | output: \n",
      "    {'accuracy': 0.37726563,\n",
      "     'learning_rate': 0.09381534,\n",
      "     'top_5_accuracy': 0.8666406,\n",
      "     'training_loss': 1.98229}\n",
      "train | step:    900 | steps/sec:   73.4 | output: \n",
      "    {'accuracy': 0.38625,\n",
      "     'learning_rate': 0.092216395,\n",
      "     'top_5_accuracy': 0.8811719,\n",
      "     'training_loss': 1.9290609}\n",
      "train | step:   1000 | steps/sec:   72.9 | output: \n",
      "    {'accuracy': 0.40523437,\n",
      "     'learning_rate': 0.090450846,\n",
      "     'top_5_accuracy': 0.886875,\n",
      "     'training_loss': 1.8887813}\n",
      " eval | step:   1000 | running 78 steps of evaluation...\n",
      " eval | step:   1000 | steps/sec:   48.6 | eval time:    1.6 sec | output: \n",
      "    {'accuracy': 0.46384215,\n",
      "     'steps_per_second': 48.557556583074124,\n",
      "     'top_5_accuracy': 0.9084535,\n",
      "     'validation_loss': 1.7426386}\n",
      "train | step:   1000 | training until step 2000...\n",
      "train | step:   1100 | steps/sec:   34.2 | output: \n",
      "    {'accuracy': 0.41789064,\n",
      "     'learning_rate': 0.08852567,\n",
      "     'top_5_accuracy': 0.8876563,\n",
      "     'training_loss': 1.8591073}\n",
      "train | step:   1200 | steps/sec:   75.7 | output: \n",
      "    {'accuracy': 0.42039064,\n",
      "     'learning_rate': 0.08644843,\n",
      "     'top_5_accuracy': 0.8876563,\n",
      "     'training_loss': 1.8593277}\n",
      "train | step:   1300 | steps/sec:   67.6 | output: \n",
      "    {'accuracy': 0.43359375,\n",
      "     'learning_rate': 0.08422736,\n",
      "     'top_5_accuracy': 0.8994531,\n",
      "     'training_loss': 1.8075901}\n",
      "train | step:   1400 | steps/sec:   67.3 | output: \n",
      "    {'accuracy': 0.43171874,\n",
      "     'learning_rate': 0.081871204,\n",
      "     'top_5_accuracy': 0.8996875,\n",
      "     'training_loss': 1.7977909}\n",
      "train | step:   1500 | steps/sec:   67.8 | output: \n",
      "    {'accuracy': 0.4477344,\n",
      "     'learning_rate': 0.07938927,\n",
      "     'top_5_accuracy': 0.9032813,\n",
      "     'training_loss': 1.7712984}\n",
      "train | step:   1600 | steps/sec:   67.6 | output: \n",
      "    {'accuracy': 0.44515625,\n",
      "     'learning_rate': 0.07679134,\n",
      "     'top_5_accuracy': 0.90054685,\n",
      "     'training_loss': 1.7786701}\n",
      "train | step:   1700 | steps/sec:   67.2 | output: \n",
      "    {'accuracy': 0.45171875,\n",
      "     'learning_rate': 0.07408768,\n",
      "     'top_5_accuracy': 0.9074219,\n",
      "     'training_loss': 1.7393799}\n",
      "train | step:   1800 | steps/sec:   67.7 | output: \n",
      "    {'accuracy': 0.4578125,\n",
      "     'learning_rate': 0.071288966,\n",
      "     'top_5_accuracy': 0.9077344,\n",
      "     'training_loss': 1.7311434}\n",
      "train | step:   1900 | steps/sec:   67.2 | output: \n",
      "    {'accuracy': 0.47507814,\n",
      "     'learning_rate': 0.068406224,\n",
      "     'top_5_accuracy': 0.9125,\n",
      "     'training_loss': 1.7006656}\n",
      "train | step:   2000 | steps/sec:   67.9 | output: \n",
      "    {'accuracy': 0.46984375,\n",
      "     'learning_rate': 0.06545085,\n",
      "     'top_5_accuracy': 0.908125,\n",
      "     'training_loss': 1.7086806}\n",
      " eval | step:   2000 | running 78 steps of evaluation...\n",
      " eval | step:   2000 | steps/sec:  207.5 | eval time:    0.4 sec | output: \n",
      "    {'accuracy': 0.5355569,\n",
      "     'steps_per_second': 207.4506632408155,\n",
      "     'top_5_accuracy': 0.94300884,\n",
      "     'validation_loss': 1.5218085}\n",
      "train | step:   2000 | training until step 3000...\n",
      "train | step:   2100 | steps/sec:   70.3 | output: \n",
      "    {'accuracy': 0.4819531,\n",
      "     'learning_rate': 0.062434502,\n",
      "     'top_5_accuracy': 0.91296875,\n",
      "     'training_loss': 1.6731693}\n",
      "train | step:   2200 | steps/sec:   78.7 | output: \n",
      "    {'accuracy': 0.49109375,\n",
      "     'learning_rate': 0.059369065,\n",
      "     'top_5_accuracy': 0.9210156,\n",
      "     'training_loss': 1.6436588}\n",
      "train | step:   2300 | steps/sec:   74.9 | output: \n",
      "    {'accuracy': 0.49375,\n",
      "     'learning_rate': 0.056266654,\n",
      "     'top_5_accuracy': 0.92195314,\n",
      "     'training_loss': 1.6347036}\n",
      "train | step:   2400 | steps/sec:   77.2 | output: \n",
      "    {'accuracy': 0.51609373,\n",
      "     'learning_rate': 0.053139526,\n",
      "     'top_5_accuracy': 0.92679685,\n",
      "     'training_loss': 1.5853946}\n",
      "train | step:   2500 | steps/sec:   85.7 | output: \n",
      "    {'accuracy': 0.5076563,\n",
      "     'learning_rate': 0.049999997,\n",
      "     'top_5_accuracy': 0.9236719,\n",
      "     'training_loss': 1.5955527}\n",
      "train | step:   2600 | steps/sec:   80.0 | output: \n",
      "    {'accuracy': 0.5141406,\n",
      "     'learning_rate': 0.04686048,\n",
      "     'top_5_accuracy': 0.9225781,\n",
      "     'training_loss': 1.5851418}\n",
      "train | step:   2700 | steps/sec:   82.8 | output: \n",
      "    {'accuracy': 0.51375,\n",
      "     'learning_rate': 0.043733336,\n",
      "     'top_5_accuracy': 0.929375,\n",
      "     'training_loss': 1.5815902}\n",
      "train | step:   2800 | steps/sec:   88.5 | output: \n",
      "    {'accuracy': 0.52085936,\n",
      "     'learning_rate': 0.040630933,\n",
      "     'top_5_accuracy': 0.9227344,\n",
      "     'training_loss': 1.5703548}\n",
      "train | step:   2900 | steps/sec:   72.8 | output: \n",
      "    {'accuracy': 0.5189844,\n",
      "     'learning_rate': 0.037565507,\n",
      "     'top_5_accuracy': 0.92414063,\n",
      "     'training_loss': 1.5661}\n",
      "train | step:   3000 | steps/sec:   84.3 | output: \n",
      "    {'accuracy': 0.5192969,\n",
      "     'learning_rate': 0.034549143,\n",
      "     'top_5_accuracy': 0.9246875,\n",
      "     'training_loss': 1.5545987}\n",
      " eval | step:   3000 | running 78 steps of evaluation...\n",
      " eval | step:   3000 | steps/sec:  181.6 | eval time:    0.4 sec | output: \n",
      "    {'accuracy': 0.6206931,\n",
      "     'steps_per_second': 181.643077445837,\n",
      "     'top_5_accuracy': 0.96173877,\n",
      "     'validation_loss': 1.2881147}\n",
      "train | step:   3000 | training until step 4000...\n",
      "train | step:   3100 | steps/sec:   67.4 | output: \n",
      "    {'accuracy': 0.5265625,\n",
      "     'learning_rate': 0.03159377,\n",
      "     'top_5_accuracy': 0.9225,\n",
      "     'training_loss': 1.5591944}\n",
      "train | step:   3200 | steps/sec:   84.6 | output: \n",
      "    {'accuracy': 0.5380469,\n",
      "     'learning_rate': 0.028711034,\n",
      "     'top_5_accuracy': 0.93289065,\n",
      "     'training_loss': 1.508923}\n",
      "train | step:   3300 | steps/sec:   72.3 | output: \n",
      "    {'accuracy': 0.5453125,\n",
      "     'learning_rate': 0.025912309,\n",
      "     'top_5_accuracy': 0.9345313,\n",
      "     'training_loss': 1.4945128}\n",
      "train | step:   3400 | steps/sec:   72.3 | output: \n",
      "    {'accuracy': 0.54046875,\n",
      "     'learning_rate': 0.023208654,\n",
      "     'top_5_accuracy': 0.9345313,\n",
      "     'training_loss': 1.4970089}\n",
      "train | step:   3500 | steps/sec:   72.4 | output: \n",
      "    {'accuracy': 0.54015625,\n",
      "     'learning_rate': 0.020610739,\n",
      "     'top_5_accuracy': 0.92828125,\n",
      "     'training_loss': 1.5085297}\n",
      "train | step:   3600 | steps/sec:   83.6 | output: \n",
      "    {'accuracy': 0.5492188,\n",
      "     'learning_rate': 0.018128792,\n",
      "     'top_5_accuracy': 0.93210936,\n",
      "     'training_loss': 1.4825172}\n",
      "train | step:   3700 | steps/sec:   72.5 | output: \n",
      "    {'accuracy': 0.56039065,\n",
      "     'learning_rate': 0.015772644,\n",
      "     'top_5_accuracy': 0.9346875,\n",
      "     'training_loss': 1.4523071}\n",
      "train | step:   3800 | steps/sec:   72.8 | output: \n",
      "    {'accuracy': 0.5611719,\n",
      "     'learning_rate': 0.01355157,\n",
      "     'top_5_accuracy': 0.9366406,\n",
      "     'training_loss': 1.4538832}\n",
      "train | step:   3900 | steps/sec:   77.0 | output: \n",
      "    {'accuracy': 0.5632031,\n",
      "     'learning_rate': 0.011474336,\n",
      "     'top_5_accuracy': 0.9369531,\n",
      "     'training_loss': 1.4498476}\n",
      "train | step:   4000 | steps/sec:   82.7 | output: \n",
      "    {'accuracy': 0.56476563,\n",
      "     'learning_rate': 0.009549147,\n",
      "     'top_5_accuracy': 0.9346875,\n",
      "     'training_loss': 1.4558712}\n",
      " eval | step:   4000 | running 78 steps of evaluation...\n",
      " eval | step:   4000 | steps/sec:  211.6 | eval time:    0.4 sec | output: \n",
      "    {'accuracy': 0.6545473,\n",
      "     'steps_per_second': 211.61443959536842,\n",
      "     'top_5_accuracy': 0.96875,\n",
      "     'validation_loss': 1.189835}\n",
      "train | step:   4000 | training until step 5000...\n",
      "train | step:   4100 | steps/sec:   68.9 | output: \n",
      "    {'accuracy': 0.56539065,\n",
      "     'learning_rate': 0.0077836006,\n",
      "     'top_5_accuracy': 0.9383594,\n",
      "     'training_loss': 1.4414221}\n",
      "train | step:   4200 | steps/sec:   95.2 | output: \n",
      "    {'accuracy': 0.57554686,\n",
      "     'learning_rate': 0.0061846706,\n",
      "     'top_5_accuracy': 0.93859375,\n",
      "     'training_loss': 1.4240199}\n",
      "train | step:   4300 | steps/sec:   65.6 | output: \n",
      "    {'accuracy': 0.5726563,\n",
      "     'learning_rate': 0.0047586444,\n",
      "     'top_5_accuracy': 0.9382031,\n",
      "     'training_loss': 1.4444406}\n",
      "train | step:   4400 | steps/sec:   72.8 | output: \n",
      "    {'accuracy': 0.5589844,\n",
      "     'learning_rate': 0.0035111725,\n",
      "     'top_5_accuracy': 0.9385156,\n",
      "     'training_loss': 1.4526067}\n",
      "train | step:   4500 | steps/sec:   74.1 | output: \n",
      "    {'accuracy': 0.5553906,\n",
      "     'learning_rate': 0.002447176,\n",
      "     'top_5_accuracy': 0.93429685,\n",
      "     'training_loss': 1.4645183}\n",
      "train | step:   4600 | steps/sec:   74.1 | output: \n",
      "    {'accuracy': 0.5679687,\n",
      "     'learning_rate': 0.0015708387,\n",
      "     'top_5_accuracy': 0.939375,\n",
      "     'training_loss': 1.4418967}\n",
      "train | step:   4700 | steps/sec:   73.3 | output: \n",
      "    {'accuracy': 0.55359375,\n",
      "     'learning_rate': 0.0008856386,\n",
      "     'top_5_accuracy': 0.93109375,\n",
      "     'training_loss': 1.4804711}\n",
      "train | step:   4800 | steps/sec:   74.3 | output: \n",
      "    {'accuracy': 0.55476564,\n",
      "     'learning_rate': 0.00039426386,\n",
      "     'top_5_accuracy': 0.93640625,\n",
      "     'training_loss': 1.459857}\n",
      "train | step:   4900 | steps/sec:   74.9 | output: \n",
      "    {'accuracy': 0.5683594,\n",
      "     'learning_rate': 9.866357e-05,\n",
      "     'top_5_accuracy': 0.9434375,\n",
      "     'training_loss': 1.4355147}\n",
      "train | step:   5000 | steps/sec:   80.5 | output: \n",
      "    {'accuracy': 0.58453125,\n",
      "     'learning_rate': 0.0,\n",
      "     'top_5_accuracy': 0.9441406,\n",
      "     'training_loss': 1.401754}\n",
      " eval | step:   5000 | running 78 steps of evaluation...\n",
      " eval | step:   5000 | steps/sec:  204.4 | eval time:    0.4 sec | output: \n",
      "    {'accuracy': 0.67978764,\n",
      "     'steps_per_second': 204.40307845717263,\n",
      "     'top_5_accuracy': 0.9720553,\n",
      "     'validation_loss': 1.1223646}\n",
      "saved checkpoint to /tmp/tmprhf7315d/ckpt-5000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:38:21.986698: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.986782: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-01-31 18:38:21.986827: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-01-31 18:38:21.987061: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.987163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.987255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.987374: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.987468: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:38:21.987527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5015 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harris/.local/lib/python3.10/site-packages/tensorflow/python/ops/nn_ops.py:5256: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harris/.local/lib/python3.10/site-packages/tensorflow/python/ops/nn_ops.py:5256: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eval | step:   5000 | running 78 steps of evaluation...\n",
      " eval | step:   5000 | steps/sec:  211.8 | eval time:    0.4 sec | output: \n",
      "    {'accuracy': 0.67978764,\n",
      "     'steps_per_second': 211.75318870203355,\n",
      "     'top_5_accuracy': 0.9720553,\n",
      "     'validation_loss': 1.1223646}\n"
     ]
    }
   ],
   "source": [
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy            : 0.680\n",
      "top_5_accuracy      : 0.972\n",
      "validation_loss     : 1.122\n",
      "steps_per_second    : 211.753\n"
     ]
    }
   ],
   "source": [
    "for key, value in eval_logs.items():\n",
    "    if isinstance(value, tf.Tensor):\n",
    "      value = value.numpy()\n",
    "    print(f'{key:20}: {value:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:40:16.466345: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  predictions = model.predict(images)\n",
    "  predictions = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "show_batch(images, labels, tf.cast(predictions, tf.int32))\n",
    "\n",
    "if device=='CPU':\n",
    "  plt.suptitle('The model was only trained for a few steps, it is not expected to do well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:40:52.223077: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./export/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./export/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving and exporting the trained model\n",
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[32, 32],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(model_dir),\n",
    "    export_dir='./export/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SavedModel\n",
    "imported = tf.saved_model.load('./export/')\n",
    "model_fn = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:41:36.134942: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for data in tfds.load('cifar10', split='test').batch(12).take(1):\n",
    "  predictions = []\n",
    "  for image in data['image']:\n",
    "    index = tf.argmax(model_fn(image[tf.newaxis, ...])['logits'], axis=1)[0]\n",
    "    predictions.append(index)\n",
    "  show_batch(data['image'], data['label'], predictions)\n",
    "\n",
    "  if device=='CPU':\n",
    "    plt.suptitle('The model was only trained for a few steps, it is not expected to do better than random.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
