{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:53:14.521111: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 18:53:14.521135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 18:53:14.521756: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 18:53:14.525557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 18:53:15.224467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import tqdm\n",
    "import shutil\n",
    "import pprint\n",
    "import pathlib\n",
    "import tempfile\n",
    "import requests\n",
    "import collections\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from etils import epath\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harris/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import orbit\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.data import tfrecord_lib\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.ops.preprocess_ops import normalize_image, resize_and_crop_image\n",
    "from official.vision.data.create_coco_tf_record import coco_annotations_to_lists\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_INVALID_ANNOTATIONS = [\n",
    "    # Train split.\n",
    "    662101,\n",
    "    81217,\n",
    "    462924,\n",
    "    227817,\n",
    "    29381,\n",
    "    601484,\n",
    "    412185,\n",
    "    504667,\n",
    "    572573,\n",
    "    91937,\n",
    "    239022,\n",
    "    181534,\n",
    "    101685,\n",
    "    # Validation split.\n",
    "    36668,\n",
    "    57541,\n",
    "    33126,\n",
    "    10932,\n",
    "]\n",
    "\n",
    "def get_category_map(annotation_path, num_classes):\n",
    "  with epath.Path(annotation_path).open() as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "  category_map = {id+1: {'id': cat_dict['id'],\n",
    "                       'name': cat_dict['name']}\n",
    "                  for id, cat_dict in enumerate(data['categories'][:num_classes])}\n",
    "  return category_map\n",
    "\n",
    "class LvisAnnotation:\n",
    "  \"\"\"LVIS annotation helper class.\n",
    "  The format of the annations is explained on\n",
    "  https://www.lvisdataset.org/dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, annotation_path):\n",
    "    with epath.Path(annotation_path).open() as f:\n",
    "      data = json.load(f)\n",
    "    self._data = data\n",
    "\n",
    "    img_id2annotations = collections.defaultdict(list)\n",
    "    for a in self._data.get('annotations', []):\n",
    "      if a['category_id'] in category_ids:\n",
    "        img_id2annotations[a['image_id']].append(a)\n",
    "    self._img_id2annotations = {\n",
    "        k: list(sorted(v, key=lambda a: a['id']))\n",
    "        for k, v in img_id2annotations.items()\n",
    "    }\n",
    "\n",
    "  @property\n",
    "  def categories(self):\n",
    "    \"\"\"Return the category dicts, as sorted in the file.\"\"\"\n",
    "    return self._data['categories']\n",
    "\n",
    "  @property\n",
    "  def images(self):\n",
    "    \"\"\"Return the image dicts, as sorted in the file.\"\"\"\n",
    "    sub_images = []\n",
    "    for image_info in self._data['images']:\n",
    "      if image_info['id'] in self._img_id2annotations:\n",
    "        sub_images.append(image_info)\n",
    "    return sub_images\n",
    "\n",
    "  def get_annotations(self, img_id):\n",
    "    \"\"\"Return all annotations associated with the image id string.\"\"\"\n",
    "    # Some images don't have any annotations. Return empty list instead.\n",
    "    return self._img_id2annotations.get(img_id, [])\n",
    "\n",
    "def _generate_tf_records(prefix, images_zip, annotation_file, num_shards=5):\n",
    "    \"\"\"Generate TFRecords.\"\"\"\n",
    "\n",
    "    lvis_annotation = LvisAnnotation(annotation_file)\n",
    "\n",
    "    def _process_example(prefix, image_info, id_to_name_map):\n",
    "      # Search image dirs.\n",
    "      filename = pathlib.Path(image_info['coco_url']).name\n",
    "      image = tf.io.read_file(os.path.join(IMGS_DIR, filename))\n",
    "      instances = lvis_annotation.get_annotations(img_id=image_info['id'])\n",
    "      instances = [x for x in instances if x['id'] not in _INVALID_ANNOTATIONS]\n",
    "      # print([x['category_id'] for x in instances])\n",
    "      is_crowd = {'iscrowd': 0}\n",
    "      instances = [dict(x, **is_crowd) for x in instances]\n",
    "      neg_category_ids = image_info.get('neg_category_ids', [])\n",
    "      not_exhaustive_category_ids = image_info.get(\n",
    "          'not_exhaustive_category_ids', []\n",
    "      )\n",
    "      data, _ = coco_annotations_to_lists(instances,\n",
    "                                          id_to_name_map,\n",
    "                                          image_info['height'],\n",
    "                                          image_info['width'],\n",
    "                                          include_masks=True)\n",
    "      # data['category_id'] = [id-1 for id in data['category_id']]\n",
    "      keys_to_features = {\n",
    "          'image/encoded':\n",
    "              tfrecord_lib.convert_to_feature(image.numpy()),\n",
    "          'image/filename':\n",
    "               tfrecord_lib.convert_to_feature(filename.encode('utf8')),\n",
    "          'image/format':\n",
    "              tfrecord_lib.convert_to_feature('jpg'.encode('utf8')),\n",
    "          'image/height':\n",
    "              tfrecord_lib.convert_to_feature(image_info['height']),\n",
    "          'image/width':\n",
    "              tfrecord_lib.convert_to_feature(image_info['width']),\n",
    "          'image/source_id':\n",
    "              tfrecord_lib.convert_to_feature(str(image_info['id']).encode('utf8')),\n",
    "          'image/object/bbox/xmin':\n",
    "              tfrecord_lib.convert_to_feature(data['xmin']),\n",
    "          'image/object/bbox/xmax':\n",
    "              tfrecord_lib.convert_to_feature(data['xmax']),\n",
    "          'image/object/bbox/ymin':\n",
    "              tfrecord_lib.convert_to_feature(data['ymin']),\n",
    "          'image/object/bbox/ymax':\n",
    "              tfrecord_lib.convert_to_feature(data['ymax']),\n",
    "          'image/object/class/text':\n",
    "              tfrecord_lib.convert_to_feature(data['category_names']),\n",
    "          'image/object/class/label':\n",
    "              tfrecord_lib.convert_to_feature(data['category_id']),\n",
    "          'image/object/is_crowd':\n",
    "              tfrecord_lib.convert_to_feature(data['is_crowd']),\n",
    "          'image/object/area':\n",
    "              tfrecord_lib.convert_to_feature(data['area'], 'float_list'),\n",
    "          'image/object/mask':\n",
    "              tfrecord_lib.convert_to_feature(data['encoded_mask_png'])\n",
    "      }\n",
    "      # print(keys_to_features['image/object/class/label'])\n",
    "      example = tf.train.Example(\n",
    "          features=tf.train.Features(feature=keys_to_features))\n",
    "      return example\n",
    "\n",
    "\n",
    "\n",
    "    # file_names = [f\"{prefix}/{pathlib.Path(image_info['coco_url']).name}\"\n",
    "    #               for image_info in lvis_annotation.images]\n",
    "    # _extract_images(images_zip, file_names)\n",
    "    writers = [\n",
    "        tf.io.TFRecordWriter(\n",
    "            tf_records_dir + prefix +'-%05d-of-%05d.tfrecord' % (i, num_shards))\n",
    "        for i in range(num_shards)\n",
    "    ]\n",
    "    id_to_name_map = {cat_dict['id']: cat_dict['name']\n",
    "                      for cat_dict in lvis_annotation.categories[:NUM_CLASSES]}\n",
    "    # print(id_to_name_map)\n",
    "    for idx, image_info in enumerate(tqdm.tqdm(lvis_annotation.images)):\n",
    "      img_data = requests.get(image_info['coco_url'], stream=True).content\n",
    "      img_name = image_info['coco_url'].split('/')[-1]\n",
    "      with open(os.path.join(IMGS_DIR, img_name), 'wb') as handler:\n",
    "          handler.write(img_data)\n",
    "      tf_example = _process_example(prefix, image_info, id_to_name_map)\n",
    "      writers[idx % num_shards].write(tf_example.SerializeToString())\n",
    "\n",
    "    del lvis_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS = {\n",
    "    'train_images': 'http://images.cocodataset.org/zips/train2017.zip',\n",
    "    'validation_images': 'http://images.cocodataset.org/zips/val2017.zip',\n",
    "    'test_images': 'http://images.cocodataset.org/zips/test2017.zip',\n",
    "}\n",
    "\n",
    "train_prefix = 'train'\n",
    "valid_prefix = 'val'\n",
    "\n",
    "train_annotation_path = './lvis_v1_train.json'\n",
    "valid_annotation_path = './lvis_v1_val.json'\n",
    "\n",
    "IMGS_DIR = './lvis_sub_dataset/'\n",
    "tf_records_dir = './lvis_tfrecords/'\n",
    "\n",
    "\n",
    "if not os.path.exists(IMGS_DIR):\n",
    "  os.mkdir(IMGS_DIR)\n",
    "\n",
    "if not os.path.exists(tf_records_dir):\n",
    "  os.mkdir(tf_records_dir)\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "category_index = get_category_map(valid_annotation_path, NUM_CLASSES)\n",
    "category_ids = list(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2338 [00:00<?, ?it/s]2024-01-31 18:57:48.349487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.389484: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.389625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.390868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.390991: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.391100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.435389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.435527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.435650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-31 18:57:48.435720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1322 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "100%|██████████| 2338/2338 [07:27<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "_generate_tf_records(train_prefix,\n",
    "                     _URLS['train_images'],\n",
    "                     train_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:37<00:00,  4.31it/s]\n"
     ]
    }
   ],
   "source": [
    "_generate_tf_records(valid_prefix,\n",
    "                     _URLS['validation_images'],\n",
    "                     valid_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_input_path = './lvis_tfrecords/train*'\n",
    "valid_data_input_path = './lvis_tfrecords/val*'\n",
    "test_data_input_path = './lvis_tfrecords/test*'\n",
    "model_dir = './trained_model/'\n",
    "export_dir ='./exported_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "  os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = exp_factory.get_exp_config('cascadercnn_spinenet_coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: gsutil: command not found\n",
      "/bin/bash: line 1: gsutil: command not found\n"
     ]
    }
   ],
   "source": [
    "model_ckpt_path = './model_ckpt/'\n",
    "if not os.path.exists(model_ckpt_path):\n",
    "  os.mkdir(model_ckpt_path)\n",
    "\n",
    "!gsutil cp gs://tf_model_garden/vision/mobilenet/v2_1.0_float/ckpt-180648.data-00000-of-00001 './model_ckpt/'\n",
    "!gsutil cp gs://tf_model_garden/vision/mobilenet/v2_1.0_float/ckpt-180648.index './model_ckpt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SHAPE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "\n",
    "# Backbone Config\n",
    "exp_config.task.annotation_file = None\n",
    "exp_config.task.freeze_backbone = True\n",
    "exp_config.task.init_checkpoint = \"./model_ckpt/ckpt-180648\"\n",
    "exp_config.task.init_checkpoint_modules = \"backbone\"\n",
    "\n",
    "# Model Config\n",
    "exp_config.task.model.num_classes = NUM_CLASSES + 1\n",
    "exp_config.task.model.input_size = IMG_SHAPE\n",
    "\n",
    "# Training Data Config\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = BATCH_SIZE\n",
    "exp_config.task.train_data.shuffle_buffer_size = 64\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation Data Config\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = BATCH_SIZE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
